import pandas as pd
import numpy as np
import shap
import inspect
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor


# ================================
# è®ºæ–‡çº§ç»˜å›¾å‚æ•°ï¼ˆå…¨å±€ï¼‰
# ================================
plt.rcParams["font.family"] = "Arial"
plt.rcParams["figure.dpi"] = 300
plt.rcParams["axes.titlesize"] = 14
plt.rcParams["axes.labelsize"] = 12
plt.rcParams["xtick.labelsize"] = 11
plt.rcParams["ytick.labelsize"] = 11
plt.rcParams["legend.fontsize"] = 11


# =========================================================
# OneHotEncoder é€‚é…æ–°æ—§ sklearn
# =========================================================
def make_ohe():
    params = inspect.signature(OneHotEncoder).parameters
    if "sparse_output" in params:
        return OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    else:
        return OneHotEncoder(handle_unknown="ignore", sparse=False)


# =========================================================
# æ ¹æ® Alloy æå– 1â€“7 ç³»
# =========================================================
def add_series_column(df):
    df = df.copy()
    df["Series"] = df["Alloy"].astype(str).str.extract(r"^(\d)").astype(float)
    df = df[df["Series"].isin([1, 2, 3, 4, 5, 6, 7])]
    df["Series"] = df["Series"].astype(int)
    return df


# =========================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼š7ä¸ªä¸“å®¶æ¨¡å‹ â†’ series-level mean(|SHAP|)
# =========================================================
def train_experts_and_get_shap(excel_file, sheet_name, target_col):

    df = pd.read_excel(excel_file, sheet_name=sheet_name)
    df = add_series_column(df)

    y_all = df[target_col]
    feature_cols = [c for c in df.columns if c not in ["Series", "Alloy", target_col]]
    X_all = df[feature_cols]
    series_all = df["Series"]

    # æ•°å€¼ / ç±»åˆ«ç‰¹å¾
    num_cols = X_all.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = [c for c in X_all.columns if c not in num_cols]

    # ---------- å…¨å±€ OHE + æ ‡å‡†åŒ– ----------
    ohe = make_ohe()
    preprocess = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), num_cols),
            ("cat", ohe, cat_cols),
        ]
    )
    preprocess.fit(X_all)

    # ---------- åˆ†å±‚æŠ½æ · ----------
    (
        X_train, X_test,
        y_train, y_test,
        series_train, series_test
    ) = train_test_split(
        X_all, y_all, series_all,
        test_size=0.2,
        random_state=42,
        stratify=series_all
    )

    # å…¨å±€ transform
    X_train_pre = preprocess.transform(X_train)

    # ç‰¹å¾å
    num_f = list(num_cols)
    if len(cat_cols) > 0:
        try:
            ohe_f = list(ohe.get_feature_names_out(cat_cols))
        except:
            ohe_f = []
    else:
        ohe_f = []
    feature_names = num_f + ohe_f

    # ---------- é€ç³»åˆ—è®¡ç®—ä¸“å®¶ SHAP ----------
    shap_dict = {}
    series_train_arr = series_train.values

    for s in range(1, 8):

        idx_s = np.where(series_train_arr == s)[0]
        if len(idx_s) < 2:
            print(f"Series {s}: æ ·æœ¬ä¸è¶³ï¼ˆ{len(idx_s)}ï¼‰ï¼Œè·³è¿‡ã€‚")
            continue

        X_s = X_train_pre[idx_s]
        y_s = y_train.iloc[idx_s]

        # éšæœºæ£®æ—ä¸“å®¶
        rf = RandomForestRegressor(
            n_estimators=300,
            random_state=42
        )
        rf.fit(X_s, y_s)

        # SHAPï¼ˆå–ç»å¯¹å€¼å¹³å‡ï¼‰
        explainer = shap.TreeExplainer(rf)
        shap_vals = explainer.shap_values(X_s)

        shap_dict[s] = np.abs(shap_vals).mean(axis=0)

        print(f"Series {s}: SHAP å·²è®¡ç®—å®Œæˆï¼Œæ ·æœ¬æ•° = {len(idx_s)}")

    return shap_dict, feature_names


# =========================================================
# 7 ç³»åˆ—çš„ beeswarmï¼ˆä½ åŸæœ¬ç”¨æ¥æ›¿ä»£æŸ±çŠ¶å›¾çš„ç‰ˆæœ¬ï¼‰
# =========================================================
def plot_beeswarm(shap_dict, feature_names, title, save_prefix):

    os.makedirs("shap_figures", exist_ok=True)

    if not shap_dict:
        print(f"{title}: æ—  SHAP æ•°æ®ï¼Œè·³è¿‡ã€‚")
        return

    # åˆå¹¶æ‰€æœ‰ series çš„ SHAPï¼Œå½¢æˆ matrix
    shap_matrix = np.vstack([shap_dict[s] for s in sorted(shap_dict.keys())])
    n_features = shap_matrix.shape[1]

    # ç‰¹å¾åè¡¥é½
    if len(feature_names) < n_features:
        extra = [f"Feature_{i}" for i in range(len(feature_names), n_features)]
        feature_names = feature_names + extra

    # é€‰å– top20 ç‰¹å¾
    top_k = min(20, n_features)
    top_idx = np.argsort(np.mean(shap_matrix, axis=0))[-top_k:][::-1]

    shap_top = shap_matrix[:, top_idx]
    feature_top_names = [feature_names[i] for i in top_idx]

    # ------------------------ è‡ªåˆ¶ beeswarm -------------------------
    fig, ax = plt.subplots(figsize=(10, 7))

    for i in range(top_k):
        sv = shap_top[:, i]
        y = np.random.normal(i, 0.12, size=len(sv))
        ax.scatter(sv, y, s=18, alpha=0.6, color="#1f77b4")

    ax.set_yticks(range(top_k))
    ax.set_yticklabels(feature_top_names)
    ax.set_xlabel("mean(|SHAP value|)")
    ax.set_title(title)
    ax.invert_yaxis()

    plt.tight_layout()
    fig.savefig(f"shap_figures/{save_prefix}.png", dpi=300)
    fig.savefig(f"shap_figures/{save_prefix}.pdf")
    plt.close()

    print(f"âœ” Series-level Beeswarm SHAP å›¾å·²ç”Ÿæˆï¼šshap_figures/{save_prefix}.png")


# =========================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šçœŸæ­£çš„ summary plotï¼ˆé€æ ·æœ¬ + æ­£è´Ÿè´¡çŒ®ï¼‰
# =========================================================
def train_global_shap(excel_file, sheet_name, target_col):

    df = pd.read_excel(excel_file, sheet_name=sheet_name)
    df = add_series_column(df)

    y = df[target_col]
    X = df[[c for c in df.columns if c not in ["Series", "Alloy", target_col]]]

    # æ•°å€¼ / ç±»åˆ«ç‰¹å¾
    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = [c for c in X.columns if c not in num_cols]

    # ---------- ç»Ÿä¸€é¢„å¤„ç† ----------
    ohe = make_ohe()
    preprocess = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), num_cols),
            ("cat", ohe, cat_cols),
        ]
    )

    # fit + transform
    X_trans = preprocess.fit_transform(X)

    # ---------- å…³é”®ä¿®å¤ï¼šä½¿ç”¨â€œfit ä¹‹åâ€çš„ OHE ----------
    ohe_fitted = preprocess.named_transformers_["cat"]

    # è·å–ç‰¹å¾å
    num_f = num_cols
    if len(cat_cols) > 0:
        try:
            ohe_f = list(ohe_fitted.get_feature_names_out(cat_cols))
        except:
            ohe_f = []
    else:
        ohe_f = []

    feature_names = num_f + ohe_f

    # ---------- å…¨å±€æ¨¡å‹ ----------
    rf = RandomForestRegressor(
        n_estimators=300,
        random_state=42
    )
    rf.fit(X_trans, y)

    # ---------- SHAP ----------
    explainer = shap.TreeExplainer(rf)
    shap_values = explainer.shap_values(X_trans)

    return shap_values, X_trans, feature_names



# =========================================================
# summary plotï¼ˆä½ è¦çš„å…¨å±€ SHAP ç±»å‹ï¼šæ­£è´Ÿè´¡çŒ® + å…¨å±€é‡è¦æ€§ï¼‰
# =========================================================
def plot_shap_summary(shap_values, X_trans, feature_names, title, save_prefix):

    os.makedirs("shap_figures", exist_ok=True)

    plt.figure(figsize=(10, 6))
    shap.summary_plot(
        shap_values,
        X_trans,
        feature_names=feature_names,
        plot_type="dot",
        max_display=20,
        show=False,
        color_bar=False     # é¿å… matplotlib 3.8 çš„ colorbar é”™è¯¯
    )
    plt.title(title)
    plt.tight_layout()
    plt.savefig(f"shap_figures/{save_prefix}.png", dpi=300)
    plt.savefig(f"shap_figures/{save_prefix}.pdf")
    plt.close()

    print(f"âœ” Summary SHAP å›¾å·²ç”Ÿæˆï¼šshap_figures/{save_prefix}.png")


# =========================================================
# ä¸»æµç¨‹
# =========================================================
if __name__ == "__main__":

    excel_file = "YTS UTS EL sheet.xlsx"

    targets = [
        ("UTS", "UTS"),
        ("YTS", "YTS"),
        ("EL",  "EL")
    ]

    for sheet_name, target in targets:

        print(f"\n===== å¼€å§‹å¤„ç† {target} =====")

        # ç¬¬ä¸€éƒ¨åˆ†ï¼šseries-level SHAPï¼ˆä½ çš„åŸå§‹é€»è¾‘ï¼‰
        shap_dict, feature_names = train_experts_and_get_shap(
            excel_file, sheet_name, target
        )
        plot_beeswarm(
            shap_dict,
            feature_names,
            f"{target} â€” Series-level Beeswarm SHAP",
            f"{target}_SHAP_beeswarm"
        )

        # ç¬¬äºŒéƒ¨åˆ†ï¼šsummary plotï¼ˆä½ è¦çš„çœŸæ­£ SHAP å½¢å¼ï¼‰
        shap_vals, X_trans, fnames = train_global_shap(
            excel_file, sheet_name, target
        )
        plot_shap_summary(
            shap_vals, X_trans, fnames,
            f"{target} â€” SHAP Summary Plot",
            f"{target}_SHAP_summary"
        )

    print("\nğŸ‰ æ‰€æœ‰å›¾åƒå·²ç”Ÿæˆï¼ˆBeeswarm + Summaryï¼‰")
